{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa243235",
   "metadata": {},
   "source": [
    "PYTHON START HERE (RIL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d17004",
   "metadata": {},
   "source": [
    "Linear Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d034ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import joblib\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to extract RGB histograms from an image\n",
    "def extract_histogram(img):\n",
    "    hist_red = cv2.calcHist([img], [0], None, [256], [0, 256])  # Red channel\n",
    "    hist_green = cv2.calcHist([img], [1], None, [256], [0, 256])  # Green channel\n",
    "    hist_blue = cv2.calcHist([img], [2], None, [256], [0, 256])  # Blue channel\n",
    "    return np.concatenate([hist_red.flatten(), hist_green.flatten(), hist_blue.flatten()])\n",
    "\n",
    "# Function to process a single image\n",
    "def process_image(category, i):\n",
    "    img_path = f'{category}/{category} ({i}).jpg'\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is not None:\n",
    "        hist = extract_histogram(img)\n",
    "        return hist, category\n",
    "    return None, None\n",
    "\n",
    "# Load images and extract features in parallel\n",
    "def load_images_parallel(image_types, num_images):\n",
    "    results = []\n",
    "    for category in image_types:\n",
    "        with Parallel(n_jobs=-1, backend='loky') as parallel:\n",
    "            results.extend(\n",
    "                tqdm(\n",
    "                    parallel(\n",
    "                        delayed(process_image)(category, i)\n",
    "                        for i in range(1, num_images + 1)\n",
    "                    ),\n",
    "                    desc=f\"Processing {category}\",\n",
    "                    leave=False\n",
    "                )\n",
    "            )\n",
    "    features, labels = zip(*[res for res in results if res[0] is not None])\n",
    "    return np.array(features), list(labels)\n",
    "\n",
    "# Set parameters\n",
    "image_types = ['Arborio', 'Basmati', 'Ipsala', 'Jasmine', 'Karacadag']\n",
    "num_images = 10500\n",
    "\n",
    "# Process images and extract features\n",
    "print(\"Processing images in parallel...\")\n",
    "features, labels = load_images_parallel(image_types, num_images)\n",
    "\n",
    "# Standardization\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# PCA for 90% variance explained\n",
    "print(f\"Applying PCA to retain 90% variance...\")\n",
    "pca = PCA(n_components=0.90)\n",
    "features_pca = pca.fit_transform(features_scaled)\n",
    "print(f\"PCA reduced dimensions to: {features_pca.shape[1]} components.\")\n",
    "\n",
    "# Convert labels to a numerical format\n",
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_pca, labels_encoded, test_size=0.3, random_state=42)\n",
    "\n",
    "# Bayesian Optimization for Hyperparameter Tuning\n",
    "print(\"Optimizing SVM hyperparameters with Bayesian Optimization...\")\n",
    "opt = BayesSearchCV(\n",
    "    SVC(kernel='linear', random_state=42, decision_function_shape='ovr'),\n",
    "    search_spaces={\n",
    "        'C': Real(1e-2, 1e+3, prior='log-uniform')  # Regularization parameter\n",
    "    },\n",
    "    n_iter=5,\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the model with Bayesian optimization\n",
    "opt.fit(X_train, y_train)\n",
    "\n",
    "# Get best parameters from optimization\n",
    "print(f\"Best hyperparameters: {opt.best_params_}\")\n",
    "\n",
    "# Evaluate SVM with the best found parameters\n",
    "y_pred = opt.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Classification accuracy with optimized parameters: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Save the optimized model and components\n",
    "joblib.dump(opt.best_estimator_, 'svm_model_optimized_ten.pkl')\n",
    "joblib.dump(pca, 'pca_model_ten.pkl')\n",
    "joblib.dump(scaler, 'scaler_model_ten.pkl')\n",
    "joblib.dump(label_encoder, 'label_encoder_ten.pkl')\n",
    "\n",
    "# Visualizing hyperplanes and decision boundaries\n",
    "print(\"Visualizing hyperplanes and decision boundaries...\")\n",
    "\n",
    "# Reduce data to 2D for visualization\n",
    "pca_2d = PCA(n_components=2)\n",
    "features_2d = pca_2d.fit_transform(features_scaled)\n",
    "X_train_2d, X_test_2d, y_train_2d, y_test_2d = train_test_split(features_2d, labels_encoded, test_size=0.3, random_state=42)\n",
    "\n",
    "# Fit the SVM again using only the first two PCA components\n",
    "svm_2d = SVC(kernel='linear', C=opt.best_params_['C'], random_state=42, decision_function_shape='ovr')\n",
    "svm_2d.fit(X_train_2d, y_train_2d)\n",
    "\n",
    "# Create a mesh grid for plotting decision boundaries\n",
    "x_min, x_max = features_2d[:, 0].min() - 1, features_2d[:, 0].max() + 1\n",
    "y_min, y_max = features_2d[:, 1].min() - 1, features_2d[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 500), np.linspace(y_min, y_max, 500))\n",
    "\n",
    "# Predict for each point in the mesh grid\n",
    "Z = svm_2d.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# Plot the decision boundaries\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# Define a custom color map for each class\n",
    "color_map = {\n",
    "    'Arborio': 'blue',\n",
    "    'Basmati': 'orange',\n",
    "    'Ipsala': 'green',\n",
    "    'Jasmine': 'red',\n",
    "    'Karacadag': 'purple'\n",
    "}\n",
    "\n",
    "# Prepare a colormap for plotting decision boundaries\n",
    "colors = ListedColormap([color_map['Arborio'], color_map['Basmati'], color_map['Ipsala'], color_map['Jasmine'], 'red', color_map['Karacadag']])\n",
    "\n",
    "\n",
    "# Plot contour for decision regions\n",
    "ax.contourf(xx, yy, Z, alpha=0.5, cmap=colors)\n",
    "\n",
    "# Scatter plot for each class\n",
    "for i, category in enumerate(image_types):\n",
    "    idx = y_train_2d == i\n",
    "    ax.scatter(\n",
    "        X_train_2d[idx, 0],\n",
    "        X_train_2d[idx, 1],\n",
    "        label=category,\n",
    "        s=60,\n",
    "        edgecolor='k',\n",
    "        alpha=0.8\n",
    "    )\n",
    "\n",
    "# Plot settings\n",
    "ax.set_xlabel('Principal Component 1', fontsize=20, weight='bold')\n",
    "ax.set_ylabel('Principal Component 2', fontsize=20, weight='bold')\n",
    "ax.legend(loc='upper left', bbox_to_anchor=(1, 1.03), fontsize=18, title='Rice Varieties', title_fontsize=20)\n",
    "ax.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "# Display the plot\n",
    "plt.tight_layout()\n",
    "plt.suptitle('SVM Decision Boundary with Linear Kernel', fontsize=24, weight='bold')\n",
    "plt.subplots_adjust(top=0.88)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6910c247",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_recall_fscore_support, classification_report, mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from matplotlib.colors import ListedColormap\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to extract RGB histograms from an image\n",
    "def extract_histogram(img):\n",
    "    hist_red = cv2.calcHist([img], [0], None, [256], [0, 256])  # Red channel\n",
    "    hist_green = cv2.calcHist([img], [1], None, [256], [0, 256])  # Green channel\n",
    "    hist_blue = cv2.calcHist([img], [2], None, [256], [0, 256])  # Blue channel\n",
    "    return np.concatenate([hist_red.flatten(), hist_green.flatten(), hist_blue.flatten()])\n",
    "\n",
    "# Function to process a single image\n",
    "def process_image(category, i):\n",
    "    img_path = f'{category}/{category} ({i}).jpg'\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is not None:\n",
    "        hist = extract_histogram(img)\n",
    "        return hist, category\n",
    "    return None, None\n",
    "\n",
    "# Load test images in parallel with progress bar\n",
    "def load_test_images(image_types, start_idx, end_idx):\n",
    "    features, labels = [], []\n",
    "    for category in image_types:\n",
    "        with Parallel(n_jobs=-1, backend='loky') as parallel:\n",
    "            results = list(\n",
    "                tqdm(\n",
    "                    parallel(\n",
    "                        delayed(process_image)(category, i)\n",
    "                        for i in range(start_idx, end_idx + 1)\n",
    "                    ),\n",
    "                    desc=f\"Processing {category}\",\n",
    "                    leave=False\n",
    "                )\n",
    "            )\n",
    "        category_features, category_labels = zip(*[res for res in results if res[0] is not None])\n",
    "        features.extend(category_features)\n",
    "        labels.extend([category] * len(category_features))\n",
    "    return np.array(features), labels\n",
    "\n",
    "# Load the optimized model and components\n",
    "svm = joblib.load('svm_model_optimized_ten.pkl')\n",
    "pca = joblib.load('pca_model_ten.pkl')\n",
    "scaler = joblib.load('scaler_model_ten.pkl')\n",
    "label_encoder = joblib.load('label_encoder_ten.pkl')\n",
    "\n",
    "# Set parameters\n",
    "image_types = ['Arborio', 'Basmati', 'Ipsala', 'Jasmine', 'Karacadag']\n",
    "start_idx, end_idx = 10501, 15000\n",
    "\n",
    "# Load test images\n",
    "print(\"Loading and processing test images...\")\n",
    "test_features, test_labels = load_test_images(image_types, start_idx, end_idx)\n",
    "\n",
    "# Preprocess test data\n",
    "test_features_scaled = scaler.transform(test_features)\n",
    "test_features_pca = pca.transform(test_features_scaled)\n",
    "test_labels_encoded = label_encoder.transform(test_labels)\n",
    "\n",
    "# Test the model on the new data\n",
    "y_test_pred = svm.predict(test_features_pca)\n",
    "\n",
    "# Accuracy on the test set\n",
    "accuracy_test = accuracy_score(test_labels_encoded, y_test_pred)\n",
    "print(f\"\\nTest Classification Accuracy: {accuracy_test * 100:.2f}%\")\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(test_labels_encoded, y_test_pred)\n",
    "\n",
    "# Plot Confusion Matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=image_types, yticklabels=image_types)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Precision, Recall, and F1-Score\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(test_labels_encoded, y_test_pred, average=None)\n",
    "\n",
    "# Create a DataFrame to show the scores\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Precision': precision,\n",
    "    'Recall': recall,\n",
    "    'F1-Score': f1\n",
    "}, index=image_types)\n",
    "\n",
    "# Plot Precision, Recall, and F1-Score\n",
    "metrics_df.plot(kind='bar', figsize=(10, 6))\n",
    "plt.title('Precision, Recall, and F1-Score for Each Class')\n",
    "plt.xlabel('Rice Varieties')\n",
    "plt.ylabel('Scores')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display the classification report\n",
    "print(\"\\nClassification Report on Test Data:\\n\")\n",
    "print(classification_report(test_labels_encoded, y_test_pred, target_names=image_types))\n",
    "\n",
    "# PCA Scatter Plot with Decision Boundary\n",
    "print(\"\\nVisualizing Decision Boundaries with PCA Scatter Plot...\")\n",
    "\n",
    "# Reduce data to 2D for visualization\n",
    "pca_2d = PCA(n_components=2)\n",
    "test_features_2d = pca_2d.fit_transform(test_features_scaled)\n",
    "\n",
    "# Fit a new SVM for visualization\n",
    "svm_2d = SVC(kernel='linear', C=svm.C, random_state=42)\n",
    "svm_2d.fit(test_features_2d, test_labels_encoded)\n",
    "\n",
    "# Create mesh grid for decision boundary\n",
    "x_min, x_max = test_features_2d[:, 0].min() - 1, test_features_2d[:, 0].max() + 1\n",
    "y_min, y_max = test_features_2d[:, 1].min() - 1, test_features_2d[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 500), np.linspace(y_min, y_max, 500))\n",
    "\n",
    "# Predict on the mesh grid\n",
    "Z = svm_2d.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# Define a custom color map for each class\n",
    "color_map = {\n",
    "    'Arborio': 'blue',\n",
    "    'Basmati': 'orange',\n",
    "    'Ipsala': 'green',\n",
    "    'Jasmine': 'red',\n",
    "    'Karacadag': 'purple'\n",
    "}\n",
    "\n",
    "# Prepare a colormap for plotting decision boundaries\n",
    "cmap = ListedColormap([color_map['Arborio'], color_map['Basmati'], color_map['Ipsala'], color_map['Jasmine'], 'red', color_map['Karacadag']])\n",
    "\n",
    "# Create the plot\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "# Plot the decision boundaries\n",
    "ax.contourf(xx, yy, Z, alpha=0.5, cmap=cmap)\n",
    "\n",
    "# Plot the data points with specified colors\n",
    "for i, category in enumerate(image_types):\n",
    "    idx = test_labels_encoded == i\n",
    "    ax.scatter(\n",
    "        test_features_2d[idx, 0],\n",
    "        test_features_2d[idx, 1],\n",
    "        label=category,\n",
    "        s=60,\n",
    "        alpha=0.8,\n",
    "        color=color_map[category]\n",
    "    )\n",
    "\n",
    "# Customize plot settings\n",
    "ax.set_xlabel('Principal Component 1', fontsize=20, weight='bold')\n",
    "ax.set_ylabel('Principal Component 2', fontsize=20, weight='bold')\n",
    "ax.legend(loc='upper left', bbox_to_anchor=(1, 1.03), fontsize=18, title='Rice Varieties', title_fontsize=20)\n",
    "ax.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "# Set plot title and layout\n",
    "plt.tight_layout()\n",
    "plt.suptitle('SVM Decision Boundary with Linear Kernel', fontsize=24, weight='bold')\n",
    "plt.subplots_adjust(top=0.88)\n",
    "plt.show()\n",
    "\n",
    "# RMSE Calculation\n",
    "rmse_test = np.sqrt(mean_squared_error(test_labels_encoded, y_test_pred))\n",
    "print(f\"\\nTest RMSE (Root Mean Square Error): {rmse_test:.4f}\")\n",
    "\n",
    "# MAE Calculation\n",
    "mae_test = mean_absolute_error(test_labels_encoded, y_test_pred)\n",
    "print(f\"Test MAE (Mean Absolute Error): {mae_test:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170e6ab4",
   "metadata": {},
   "source": [
    "RBF KERNEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6f2dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import joblib\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to extract RGB histograms from an image\n",
    "def extract_histogram(img):\n",
    "    hist_red = cv2.calcHist([img], [0], None, [256], [0, 256])  # Red channel\n",
    "    hist_green = cv2.calcHist([img], [1], None, [256], [0, 256])  # Green channel\n",
    "    hist_blue = cv2.calcHist([img], [2], None, [256], [0, 256])  # Blue channel\n",
    "    return np.concatenate([hist_red.flatten(), hist_green.flatten(), hist_blue.flatten()])\n",
    "\n",
    "# Function to process a single image\n",
    "def process_image(category, i):\n",
    "    img_path = f'{category}/{category} ({i}).jpg'\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is not None:\n",
    "        hist = extract_histogram(img)\n",
    "        return hist, category\n",
    "    return None, None\n",
    "\n",
    "# Load images and extract features in parallel\n",
    "def load_images_parallel(image_types, num_images):\n",
    "    results = []\n",
    "    for category in image_types:\n",
    "        with Parallel(n_jobs=-1, backend='loky') as parallel:\n",
    "            results.extend(\n",
    "                tqdm(\n",
    "                    parallel(\n",
    "                        delayed(process_image)(category, i)\n",
    "                        for i in range(1, num_images + 1)\n",
    "                    ),\n",
    "                    desc=f\"Processing {category}\",\n",
    "                    leave=False\n",
    "                )\n",
    "            )\n",
    "    features, labels = zip(*[res for res in results if res[0] is not None])\n",
    "    return np.array(features), list(labels)\n",
    "\n",
    "# Set parameters\n",
    "image_types = ['Arborio', 'Basmati', 'Ipsala', 'Jasmine', 'Karacadag']\n",
    "num_images = 10500\n",
    "\n",
    "# Process images and extract features\n",
    "print(\"Processing images in parallel...\")\n",
    "features, labels = load_images_parallel(image_types, num_images)\n",
    "\n",
    "# Standardization\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# PCA for 90% variance explained\n",
    "print(f\"Applying PCA to retain 90% variance...\")\n",
    "pca = PCA(n_components=0.90)\n",
    "features_pca = pca.fit_transform(features_scaled)\n",
    "print(f\"PCA reduced dimensions to: {features_pca.shape[1]} components.\")\n",
    "\n",
    "# Convert labels to a numerical format\n",
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_pca, labels_encoded, test_size=0.3, random_state=42)\n",
    "\n",
    "# Bayesian Optimization for Hyperparameter Tuning\n",
    "print(\"Optimizing SVM hyperparameters with Bayesian Optimization...\")\n",
    "opt = BayesSearchCV(\n",
    "    SVC(kernel='rbf', random_state=42),\n",
    "    search_spaces={\n",
    "        'C': Real(1e-2, 1e+3, prior='log-uniform'),  # Regularization parameter\n",
    "        'gamma': Real(1e-4, 1e-1, prior='log-uniform')  # Kernel coefficient\n",
    "    },\n",
    "    n_iter=5,\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the model with Bayesian optimization\n",
    "opt.fit(X_train, y_train)\n",
    "\n",
    "# Get best parameters from optimization\n",
    "print(f\"Best hyperparameters: {opt.best_params_}\")\n",
    "\n",
    "# Evaluate SVM with the best found parameters\n",
    "y_pred = opt.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Classification accuracy with optimized parameters: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Save the optimized model and components\n",
    "joblib.dump(opt.best_estimator_, 'RBF_svm_model_optimized_ten.pkl')\n",
    "joblib.dump(pca, 'RBF_pca_model_ten.pkl')\n",
    "joblib.dump(scaler, 'RBF_scaler_model_ten.pkl')\n",
    "joblib.dump(label_encoder, 'RBF_label_encoder_ten.pkl')\n",
    "\n",
    "# Visualizing hyperplanes and decision boundaries\n",
    "print(\"Visualizing decision boundaries...\")\n",
    "\n",
    "# Reduce data to 2D for visualization\n",
    "pca_2d = PCA(n_components=2)\n",
    "features_2d = pca_2d.fit_transform(features_scaled)\n",
    "X_train_2d, X_test_2d, y_train_2d, y_test_2d = train_test_split(features_2d, labels_encoded, test_size=0.3, random_state=42)\n",
    "\n",
    "# Fit the SVM again using only the first two PCA components\n",
    "svm_2d = SVC(kernel='rbf', C=opt.best_params_['C'], gamma=opt.best_params_['gamma'], random_state=42)\n",
    "svm_2d.fit(X_train_2d, y_train_2d)\n",
    "\n",
    "# Create a mesh grid for plotting decision boundaries\n",
    "x_min, x_max = features_2d[:, 0].min() - 1, features_2d[:, 0].max() + 1\n",
    "y_min, y_max = features_2d[:, 1].min() - 1, features_2d[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 500), np.linspace(y_min, y_max, 500))\n",
    "\n",
    "# Predict for each point in the mesh grid\n",
    "Z = svm_2d.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# Plot the decision boundaries\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# Define a custom color map for each class\n",
    "color_map = {\n",
    "    'Arborio': 'blue',\n",
    "    'Basmati': 'orange',\n",
    "    'Ipsala': 'green',\n",
    "    'Jasmine': 'red',\n",
    "    'Karacadag': 'purple'\n",
    "}\n",
    "\n",
    "# Prepare a colormap for plotting decision boundaries\n",
    "colors = ListedColormap([color_map['Arborio'], color_map['Basmati'], color_map['Ipsala'], color_map['Jasmine'], color_map['Karacadag']])\n",
    "\n",
    "# Plot contour for decision regions\n",
    "ax.contourf(xx, yy, Z, alpha=0.5, cmap=colors)\n",
    "\n",
    "# Scatter plot for each class\n",
    "for i, category in enumerate(image_types):\n",
    "    idx = y_train_2d == i\n",
    "    ax.scatter(\n",
    "        X_train_2d[idx, 0],\n",
    "        X_train_2d[idx, 1],\n",
    "        label=category,\n",
    "        s=60,\n",
    "        edgecolor='k',\n",
    "        alpha=0.8\n",
    "    )\n",
    "\n",
    "# Plot settings\n",
    "ax.set_xlabel('Principal Component 1', fontsize=20, weight='bold')\n",
    "ax.set_ylabel('Principal Component 2', fontsize=20, weight='bold')\n",
    "ax.legend(loc='upper left', bbox_to_anchor=(1, 1.03), fontsize=18, title='Rice Varieties', title_fontsize=20)\n",
    "ax.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "# Display the plot\n",
    "plt.tight_layout()\n",
    "plt.suptitle('SVM Decision Boundary with RBF Kernel', fontsize=24, weight='bold')\n",
    "plt.subplots_adjust(top=0.88)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68900e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_recall_fscore_support, classification_report, mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from matplotlib.colors import ListedColormap\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to extract RGB histograms from an image\n",
    "def extract_histogram(img):\n",
    "    hist_red = cv2.calcHist([img], [0], None, [256], [0, 256])  # Red channel\n",
    "    hist_green = cv2.calcHist([img], [1], None, [256], [0, 256])  # Green channel\n",
    "    hist_blue = cv2.calcHist([img], [2], None, [256], [0, 256])  # Blue channel\n",
    "    return np.concatenate([hist_red.flatten(), hist_green.flatten(), hist_blue.flatten()])\n",
    "\n",
    "# Function to process a single image\n",
    "def process_image(category, i):\n",
    "    img_path = f'{category}/{category} ({i}).jpg'\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is not None:\n",
    "        hist = extract_histogram(img)\n",
    "        return hist, category\n",
    "    return None, None\n",
    "\n",
    "# Load test images in parallel with progress bar\n",
    "def load_test_images(image_types, start_idx, end_idx):\n",
    "    features, labels = [], []\n",
    "    for category in image_types:\n",
    "        with Parallel(n_jobs=-1, backend='loky') as parallel:\n",
    "            results = list(\n",
    "                tqdm(\n",
    "                    parallel(\n",
    "                        delayed(process_image)(category, i)\n",
    "                        for i in range(start_idx, end_idx + 1)\n",
    "                    ),\n",
    "                    desc=f\"Processing {category}\",\n",
    "                    leave=False\n",
    "                )\n",
    "            )\n",
    "        category_features, category_labels = zip(*[res for res in results if res[0] is not None])\n",
    "        features.extend(category_features)\n",
    "        labels.extend([category] * len(category_features))\n",
    "    return np.array(features), labels\n",
    "\n",
    "# Load the optimized model and components\n",
    "svm = joblib.load('RBF_svm_model_optimized_ten.pkl')\n",
    "pca = joblib.load('RBF_pca_model_ten.pkl')\n",
    "scaler = joblib.load('RBF_scaler_model_ten.pkl')\n",
    "label_encoder = joblib.load('RBF_label_encoder_ten.pkl')\n",
    "\n",
    "# Set parameters\n",
    "image_types = ['Arborio', 'Basmati', 'Ipsala', 'Jasmine', 'Karacadag']\n",
    "start_idx, end_idx = 10501, 15000\n",
    "\n",
    "# Load test images\n",
    "print(\"Loading and processing test images...\")\n",
    "test_features, test_labels = load_test_images(image_types, start_idx, end_idx)\n",
    "\n",
    "# Preprocess test data\n",
    "test_features_scaled = scaler.transform(test_features)\n",
    "test_features_pca = pca.transform(test_features_scaled)\n",
    "test_labels_encoded = label_encoder.transform(test_labels)\n",
    "\n",
    "# Test the model on the new data\n",
    "y_test_pred = svm.predict(test_features_pca)\n",
    "\n",
    "# Accuracy on the test set\n",
    "accuracy_test = accuracy_score(test_labels_encoded, y_test_pred)\n",
    "print(f\"\\nTest Classification Accuracy: {accuracy_test * 100:.2f}%\")\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(test_labels_encoded, y_test_pred)\n",
    "\n",
    "# Plot Confusion Matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=image_types, yticklabels=image_types)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Precision, Recall, and F1-Score\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(test_labels_encoded, y_test_pred, average=None)\n",
    "\n",
    "# Create a DataFrame to show the scores\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Precision': precision,\n",
    "    'Recall': recall,\n",
    "    'F1-Score': f1\n",
    "}, index=image_types)\n",
    "\n",
    "# Plot Precision, Recall, and F1-Score\n",
    "metrics_df.plot(kind='bar', figsize=(10, 6))\n",
    "plt.title('Precision, Recall, and F1-Score for Each Class')\n",
    "plt.xlabel('Rice Varieties')\n",
    "plt.ylabel('Scores')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display the classification report\n",
    "print(\"\\nClassification Report on Test Data:\\n\")\n",
    "print(classification_report(test_labels_encoded, y_test_pred, target_names=image_types))\n",
    "\n",
    "# PCA Scatter Plot with Decision Boundary\n",
    "print(\"\\nVisualizing Decision Boundaries with PCA Scatter Plot...\")\n",
    "pca_2d = PCA(n_components=2)\n",
    "test_features_2d = pca_2d.fit_transform(test_features_scaled)\n",
    "\n",
    "# Fit a new SVM for visualization\n",
    "svm_2d = SVC(kernel='rbf', C=svm.C, gamma=svm.gamma, random_state=42)\n",
    "svm_2d.fit(test_features_2d, test_labels_encoded)\n",
    "\n",
    "# Create mesh grid for decision boundary\n",
    "x_min, x_max = test_features_2d[:, 0].min() - 1, test_features_2d[:, 0].max() + 1\n",
    "y_min, y_max = test_features_2d[:, 1].min() - 1, test_features_2d[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 500), np.linspace(y_min, y_max, 500))\n",
    "\n",
    "# Predict on the mesh grid\n",
    "Z = svm_2d.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# Define a custom color map for each class\n",
    "color_map = {\n",
    "    'Arborio': 'blue',\n",
    "    'Basmati': 'orange',\n",
    "    'Ipsala': 'green',\n",
    "    'Jasmine': 'red',\n",
    "    'Karacadag': 'purple'\n",
    "}\n",
    "\n",
    "# Prepare a colormap for plotting decision boundaries\n",
    "cmap = ListedColormap([color_map['Arborio'], color_map['Basmati'], color_map['Ipsala'], color_map['Jasmine'], color_map['Karacadag']])\n",
    "\n",
    "# Create the plot\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "# Plot the decision boundaries\n",
    "ax.contourf(xx, yy, Z, alpha=0.5, cmap=cmap)\n",
    "\n",
    "# Plot the data points with specified colors\n",
    "for i, category in enumerate(image_types):\n",
    "    idx = test_labels_encoded == i\n",
    "    ax.scatter(\n",
    "        test_features_2d[idx, 0],\n",
    "        test_features_2d[idx, 1],\n",
    "        label=category,\n",
    "        s=60,\n",
    "        alpha=0.8,\n",
    "        color=color_map[category]\n",
    "    )\n",
    "\n",
    "# Customize plot settings\n",
    "ax.set_xlabel('Principal Component 1', fontsize=20, weight='bold')\n",
    "ax.set_ylabel('Principal Component 2', fontsize=20, weight='bold')\n",
    "ax.legend(loc='upper left', bbox_to_anchor=(1, 1.03), fontsize=18, title='Rice Varieties', title_fontsize=20)\n",
    "ax.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "# Set plot title and layout\n",
    "plt.tight_layout()\n",
    "plt.suptitle('SVM Decision Boundary with RBF Kernel', fontsize=24, weight='bold')\n",
    "plt.subplots_adjust(top=0.88)\n",
    "plt.show()\n",
    "\n",
    "# RMSE Calculation\n",
    "rmse_test = np.sqrt(mean_squared_error(test_labels_encoded, y_test_pred))\n",
    "print(f\"\\nTest RMSE (Root Mean Square Error): {rmse_test:.4f}\")\n",
    "\n",
    "# MAE Calculation\n",
    "mae_test = mean_absolute_error(test_labels_encoded, y_test_pred)\n",
    "print(f\"Test MAE (Mean Absolute Error): {mae_test:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
